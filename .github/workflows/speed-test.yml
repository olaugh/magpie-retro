name: Speed Test Benchmark

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      num_games:
        description: 'Number of games to run per variant'
        required: false
        default: 50
        type: number
      test_ref:
        description: 'Git ref to test (branch, tag, or commit SHA). Leave empty for current branch.'
        required: false
        default: ''
        type: string
      baseline_ref:
        description: 'Baseline ref to compare against (default: main)'
        required: false
        default: 'main'
        type: string
      pr_number:
        description: 'PR number to post results as a comment (optional)'
        required: false
        default: ''
        type: string

permissions:
  contents: read
  pull-requests: write

env:
  # Defaults for when inputs are not available (e.g., pull_request trigger)
  DEFAULT_NUM_GAMES: 50
  DEFAULT_BASELINE_REF: main

jobs:
  # First, check if test and baseline refs resolve to the same commit
  check-refs:
    runs-on: ubuntu-latest
    outputs:
      same_commit: ${{ steps.check.outputs.same_commit }}
      test_sha: ${{ steps.check.outputs.test_sha }}
      baseline_sha: ${{ steps.check.outputs.baseline_sha }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check if refs are equivalent
        id: check
        run: |
          # For pull_request events, use github.sha directly (the merge commit)
          # since refs/pull/N/merge isn't available after a regular fetch
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            TEST_SHA="${{ github.sha }}"
            TEST_REF="PR #${{ github.event.pull_request.number }}"
          else
            TEST_REF="${{ inputs.test_ref || github.ref }}"
            TEST_SHA=$(git rev-parse "$TEST_REF" 2>/dev/null || echo "")
          fi
          BASELINE_REF="${{ inputs.baseline_ref || env.DEFAULT_BASELINE_REF }}"

          # Resolve baseline ref to commit SHA
          BASELINE_SHA=$(git rev-parse "$BASELINE_REF" 2>/dev/null || echo "")

          # Validate that both refs resolved successfully
          if [[ -z "$TEST_SHA" ]]; then
            echo "Error: Failed to resolve test ref '$TEST_REF' to a commit SHA." >&2
            exit 1
          fi
          if [[ -z "$BASELINE_SHA" ]]; then
            echo "Error: Failed to resolve baseline ref '$BASELINE_REF' to a commit SHA." >&2
            exit 1
          fi

          echo "test_sha=$TEST_SHA" >> "$GITHUB_OUTPUT"
          echo "baseline_sha=$BASELINE_SHA" >> "$GITHUB_OUTPUT"

          if [[ "$TEST_SHA" == "$BASELINE_SHA" ]]; then
            echo "same_commit=true" >> "$GITHUB_OUTPUT"
            echo "Test and baseline resolve to the same commit: $TEST_SHA"
          else
            echo "same_commit=false" >> "$GITHUB_OUTPUT"
            echo "Test: $TEST_REF -> $TEST_SHA"
            echo "Baseline: $BASELINE_REF -> $BASELINE_SHA"
          fi

  benchmark:
    runs-on: ubuntu-latest
    needs: check-refs
    outputs:
      artifact_name: ${{ steps.sanitize-test-ref.outputs.artifact_name }}
    steps:
      # Checkout with full history, then switch to the target ref.
      # This supports commit SHAs which actions/checkout can't fetch directly.
      # Submodules are initialized after switching to the correct commit.
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout target ref
        run: |
          git checkout ${{ needs.check-refs.outputs.test_sha }}
          git submodule update --init --recursive

      - name: Show test configuration
        run: |
          echo "Testing ref: ${{ inputs.test_ref || github.ref }}"
          echo "Commit: $(git rev-parse HEAD)"
          echo "Commit message: $(git log -1 --pretty=%s)"

      - name: Install Homebrew
        run: |
          /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
          echo "/home/linuxbrew/.linuxbrew/bin" >> $GITHUB_PATH
          echo "/home/linuxbrew/.linuxbrew/sbin" >> $GITHUB_PATH

      - name: Install m68k-elf toolchain via Homebrew
        run: |
          eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
          brew tap rosco-m68k/toolchain
          brew install rosco-m68k/toolchain/binutils-cross-m68k
          brew install rosco-m68k/toolchain/gcc-cross-m68k@13

      - name: Setup Bazel
        uses: bazel-contrib/setup-bazel@0.14.0
        with:
          bazelisk-cache: true
          disk-cache: ${{ github.workflow }}
          repository-cache: true

      - name: Build timing ROMs
        run: |
          eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
          make timing-builds

      - name: Run speed benchmark
        run: |
          eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
          mkdir -p results

          bazelisk run //tests/gxtest:scrabble_timing_report -- \
            -n ${{ inputs.num_games || env.DEFAULT_NUM_GAMES }} \
            -o ${{ github.workspace }}/results/timing_report.html \
            2>&1 | tee results/benchmark_output.txt

      - name: Sanitize ref for artifact name
        id: sanitize-test-ref
        run: |
          ref='${{ inputs.test_ref || github.ref_name }}'
          safe="${ref//[\/\\:*?\"<>|]/-}"
          echo "value=$safe" >> "$GITHUB_OUTPUT"
          echo "artifact_name=speed-test-${safe}-${{ github.run_number }}" >> "$GITHUB_OUTPUT"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.sanitize-test-ref.outputs.artifact_name }}
          path: results/
          retention-days: 30

  # Only run baseline if it's a different commit
  baseline:
    runs-on: ubuntu-latest
    needs: check-refs
    if: needs.check-refs.outputs.same_commit != 'true'
    outputs:
      artifact_name: ${{ steps.sanitize-baseline-ref.outputs.artifact_name }}
    steps:
      # Checkout with full history, then switch to the target ref.
      # This supports commit SHAs which actions/checkout can't fetch directly.
      # Submodules are initialized after switching to the correct commit.
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout baseline ref
        run: |
          git checkout ${{ needs.check-refs.outputs.baseline_sha }}
          git submodule update --init --recursive

      - name: Show baseline configuration
        run: |
          echo "Baseline ref: ${{ inputs.baseline_ref || env.DEFAULT_BASELINE_REF }}"
          echo "Commit: $(git rev-parse HEAD)"
          echo "Commit message: $(git log -1 --pretty=%s)"

      - name: Install Homebrew
        run: |
          /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
          echo "/home/linuxbrew/.linuxbrew/bin" >> $GITHUB_PATH
          echo "/home/linuxbrew/.linuxbrew/sbin" >> $GITHUB_PATH

      - name: Install m68k-elf toolchain via Homebrew
        run: |
          eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
          brew tap rosco-m68k/toolchain
          brew install rosco-m68k/toolchain/binutils-cross-m68k
          brew install rosco-m68k/toolchain/gcc-cross-m68k@13

      - name: Setup Bazel
        uses: bazel-contrib/setup-bazel@0.14.0
        with:
          bazelisk-cache: true
          disk-cache: ${{ github.workflow }}-baseline
          repository-cache: true

      - name: Build timing ROMs (baseline)
        run: |
          eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
          make timing-builds

      - name: Run baseline benchmark
        run: |
          eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
          mkdir -p results

          bazelisk run //tests/gxtest:scrabble_timing_report -- \
            -n ${{ inputs.num_games || env.DEFAULT_NUM_GAMES }} \
            -o ${{ github.workspace }}/results/timing_report.html \
            2>&1 | tee results/benchmark_output.txt

      - name: Sanitize baseline ref for artifact name
        id: sanitize-baseline-ref
        run: |
          ref='${{ inputs.baseline_ref || env.DEFAULT_BASELINE_REF }}'
          safe="${ref//[\/\\:*?\"<>|]/-}"
          echo "value=$safe" >> "$GITHUB_OUTPUT"
          echo "artifact_name=speed-test-baseline-${safe}-${{ github.run_number }}" >> "$GITHUB_OUTPUT"

      - name: Upload baseline results
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.sanitize-baseline-ref.outputs.artifact_name }}
          path: results/
          retention-days: 30

  # Generate comparison when we have both results
  compare:
    runs-on: ubuntu-latest
    needs: [check-refs, benchmark, baseline]
    if: needs.check-refs.outputs.same_commit != 'true'
    steps:
      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.benchmark.outputs.artifact_name }}
          path: benchmark-results

      - name: Download baseline results
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.baseline.outputs.artifact_name }}
          path: baseline-results

      - name: Generate comparison summary
        run: |
          # Note: jq and bc are pre-installed on ubuntu-latest runners
          TEST_REF="${{ inputs.test_ref || github.ref }}"
          BASELINE_REF="${{ inputs.baseline_ref || env.DEFAULT_BASELINE_REF }}"

          # Write to both step summary and a file for the PR comment
          SUMMARY_FILE="${RUNNER_TEMP}/comparison_summary.md"

          if [[ -f benchmark-results/timing_report_summary.json ]] && [[ -f baseline-results/timing_report_summary.json ]]; then
            {
              echo "## Performance Comparison"
              echo ""
              echo "| Metric | Test (\`${TEST_REF}\`) | Baseline (\`${BASELINE_REF}\`) | Change |"
              echo "|--------|------|----------|--------|"
            } | tee -a "$GITHUB_STEP_SUMMARY" > "$SUMMARY_FILE"

            # Dynamically extract lexicon names from JSON
            lexicons=$(jq -r '.lexicons[].name' benchmark-results/timing_report_summary.json)
            for lex in $lexicons; do
              test_hybrid=$(jq -r --arg lex "$lex" '.lexicons[] | select(.name == $lex) | .hybrid_mean' benchmark-results/timing_report_summary.json)
              base_hybrid=$(jq -r --arg lex "$lex" '.lexicons[] | select(.name == $lex) | .hybrid_mean' baseline-results/timing_report_summary.json)

              if [[ "$test_hybrid" != "null" ]] && [[ "$base_hybrid" != "null" ]] && [[ "$base_hybrid" != "0" ]]; then
                change=$(echo "scale=1; (($test_hybrid - $base_hybrid) / $base_hybrid) * 100" | bc)
                if (( $(echo "$change < 0" | bc -l) )); then
                  # Remove leading minus sign for display
                  change_display="${change#-}% faster"
                elif (( $(echo "$change > 0" | bc -l) )); then
                  change_display="+${change}% slower"
                else
                  change_display="0%"
                fi
                echo "| **${lex} Hybrid** | ${test_hybrid} frames | ${base_hybrid} frames | ${change_display} |" | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"
              fi
            done

            {
              echo ""
              echo "### Detailed Results"
              echo ""
              echo "<details>"
              echo "<summary>Test Results (${TEST_REF})</summary>"
              echo ""
              echo '```json'
              cat benchmark-results/timing_report_summary.json
              echo '```'
              echo "</details>"
              echo ""
              echo "<details>"
              echo "<summary>Baseline Results (${BASELINE_REF})</summary>"
              echo ""
              echo '```json'
              cat baseline-results/timing_report_summary.json
              echo '```'
              echo "</details>"
            } | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"

          elif [[ -f benchmark-results/timing_report.html ]] && [[ -f baseline-results/timing_report.html ]]; then
            # Fallback: extract overall hybrid value from HTML when JSON is not available
            # This handles comparisons against older commits that don't have JSON output
            {
              echo "## Performance Comparison"
              echo ""
              echo "_Note: Using HTML fallback for commits without JSON summary._"
              echo ""
            } | tee -a "$GITHUB_STEP_SUMMARY" > "$SUMMARY_FILE"

            # Extract the first "Hybrid (Actual)" value which is the overall average
            test_hybrid=$(grep -oP 'Hybrid \(Actual\)</div><div class="value"[^>]*>\K[0-9.]+' benchmark-results/timing_report.html | head -1)
            base_hybrid=$(grep -oP 'Hybrid \(Actual\)</div><div class="value"[^>]*>\K[0-9.]+' baseline-results/timing_report.html | head -1)

            if [[ -n "$test_hybrid" ]] && [[ -n "$base_hybrid" ]]; then
              {
                echo "| Metric | Test (\`${TEST_REF}\`) | Baseline (\`${BASELINE_REF}\`) | Change |"
                echo "|--------|------|----------|--------|"
              } | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"

              change=$(echo "scale=1; (($test_hybrid - $base_hybrid) / $base_hybrid) * 100" | bc)
              if (( $(echo "$change < 0" | bc -l) )); then
                change_display="${change#-}% faster"
              elif (( $(echo "$change > 0" | bc -l) )); then
                change_display="+${change}% slower"
              else
                change_display="0%"
              fi
              echo "| **Overall Hybrid** | ${test_hybrid} frames | ${base_hybrid} frames | ${change_display} |" | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"
            else
              echo "Could not extract timing data from HTML reports." | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"
            fi

          else
            {
              echo "## Performance Comparison"
              echo ""
              echo "Results files not found. Download the artifacts to view the reports."
            } | tee -a "$GITHUB_STEP_SUMMARY" > "$SUMMARY_FILE"
          fi

      - name: Post results to PR
        # Skip for fork PRs (GITHUB_TOKEN can't comment on forks) and when no PR context
        if: |
          (github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository) ||
          (github.event_name == 'workflow_dispatch' && inputs.pr_number != '')
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ github.event.pull_request.number || inputs.pr_number }}
        run: |
          SUMMARY_FILE="${RUNNER_TEMP}/comparison_summary.md"

          # Read the comparison summary
          if [[ -f "$SUMMARY_FILE" ]]; then
            COMMENT_BODY=$(cat "$SUMMARY_FILE")
          else
            COMMENT_BODY="Benchmark comparison complete. View the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details."
          fi

          # Add a header and link to the full workflow run
          HEADER="### Speed Test Benchmark Results"
          FOOTER="---"$'\n'"_[View full workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})_"
          FULL_COMMENT="${HEADER}"$'\n\n'"${COMMENT_BODY}"$'\n\n'"${FOOTER}"

          # Check for existing benchmark comment and update it, or create new one
          # Use --paginate to search all comments, not just first page
          EXISTING_COMMENT_ID=$(gh api --paginate \
            -H "Accept: application/vnd.github+json" \
            /repos/${{ github.repository }}/issues/${PR_NUMBER}/comments \
            --jq '.[] | select(.body | startswith("### Speed Test Benchmark Results")) | .id' \
            | head -1)

          if [[ -n "$EXISTING_COMMENT_ID" ]]; then
            gh api \
              --method PATCH \
              -H "Accept: application/vnd.github+json" \
              /repos/${{ github.repository }}/issues/comments/${EXISTING_COMMENT_ID} \
              -f body="$FULL_COMMENT"
            echo "Updated existing comment #${EXISTING_COMMENT_ID}"
          else
            gh pr comment ${PR_NUMBER} --repo ${{ github.repository }} --body "$FULL_COMMENT"
            echo "Posted new comment to PR #${PR_NUMBER}"
          fi

  # Generate summary when test and baseline are the same commit
  summary:
    runs-on: ubuntu-latest
    needs: [check-refs, benchmark]
    if: needs.check-refs.outputs.same_commit == 'true'
    steps:
      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.benchmark.outputs.artifact_name }}
          path: benchmark-results

      - name: Generate summary
        run: |
          # Note: jq is pre-installed on ubuntu-latest runners
          TEST_REF="${{ inputs.test_ref || github.ref }}"

          # Write to both step summary and a file for the PR comment
          SUMMARY_FILE="${RUNNER_TEMP}/benchmark_summary.md"

          {
            echo "## Performance Results"
            echo ""
            echo "**Ref:** \`${TEST_REF}\` (commit: \`${{ needs.check-refs.outputs.test_sha }}\`)"
            echo ""
            echo "_Note: Test and baseline refs resolve to the same commit, so no comparison is shown._"
            echo ""
          } | tee -a "$GITHUB_STEP_SUMMARY" > "$SUMMARY_FILE"

          if [[ -f benchmark-results/timing_report_summary.json ]]; then
            {
              echo "| Lexicon | Hybrid Mean | Shadow Mean | NoShadow Mean | Moves |"
              echo "|---------|-------------|-------------|---------------|-------|"
            } | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"

            # Dynamically extract lexicon names from JSON
            lexicons=$(jq -r '.lexicons[].name' benchmark-results/timing_report_summary.json)
            for lex in $lexicons; do
              hybrid=$(jq -r --arg lex "$lex" '.lexicons[] | select(.name == $lex) | .hybrid_mean' benchmark-results/timing_report_summary.json)
              shadow=$(jq -r --arg lex "$lex" '.lexicons[] | select(.name == $lex) | .shadow_mean' benchmark-results/timing_report_summary.json)
              noshadow=$(jq -r --arg lex "$lex" '.lexicons[] | select(.name == $lex) | .noshadow_mean' benchmark-results/timing_report_summary.json)
              moves=$(jq -r --arg lex "$lex" '.lexicons[] | select(.name == $lex) | .move_count' benchmark-results/timing_report_summary.json)

              if [[ "$hybrid" != "null" ]]; then
                echo "| **${lex}** | ${hybrid} frames | ${shadow} frames | ${noshadow} frames | ${moves} |" | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"
              fi
            done

            {
              echo ""
              echo "<details>"
              echo "<summary>Full JSON Summary</summary>"
              echo ""
              echo '```json'
              cat benchmark-results/timing_report_summary.json
              echo '```'
              echo "</details>"
            } | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"
          else
            echo "Summary JSON file not found. Download the artifact to view the full HTML report." | tee -a "$GITHUB_STEP_SUMMARY" >> "$SUMMARY_FILE"
          fi

      - name: Post results to PR
        # Skip for fork PRs (GITHUB_TOKEN can't comment on forks) and when no PR context
        if: |
          (github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository) ||
          (github.event_name == 'workflow_dispatch' && inputs.pr_number != '')
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ github.event.pull_request.number || inputs.pr_number }}
        run: |
          SUMMARY_FILE="${RUNNER_TEMP}/benchmark_summary.md"

          # Read the benchmark summary
          if [[ -f "$SUMMARY_FILE" ]]; then
            COMMENT_BODY=$(cat "$SUMMARY_FILE")
          else
            COMMENT_BODY="Benchmark complete. View the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details."
          fi

          # Add a header and link to the full workflow run
          HEADER="### Speed Test Benchmark Results"
          FOOTER="---"$'\n'"_[View full workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})_"
          FULL_COMMENT="${HEADER}"$'\n\n'"${COMMENT_BODY}"$'\n\n'"${FOOTER}"

          # Check for existing benchmark comment and update it, or create new one
          # Use --paginate to search all comments, not just first page
          EXISTING_COMMENT_ID=$(gh api --paginate \
            -H "Accept: application/vnd.github+json" \
            /repos/${{ github.repository }}/issues/${PR_NUMBER}/comments \
            --jq '.[] | select(.body | startswith("### Speed Test Benchmark Results")) | .id' \
            | head -1)

          if [[ -n "$EXISTING_COMMENT_ID" ]]; then
            gh api \
              --method PATCH \
              -H "Accept: application/vnd.github+json" \
              /repos/${{ github.repository }}/issues/comments/${EXISTING_COMMENT_ID} \
              -f body="$FULL_COMMENT"
            echo "Updated existing comment #${EXISTING_COMMENT_ID}"
          else
            gh pr comment ${PR_NUMBER} --repo ${{ github.repository }} --body "$FULL_COMMENT"
            echo "Posted new comment to PR #${PR_NUMBER}"
          fi
